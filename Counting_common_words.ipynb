{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enguyen120/BigDataProject/blob/main/Counting_common_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "PaG8SVYehdUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy1jk0G-g9Dh",
        "outputId": "b1a063a6-57c9-452d-d86a-1684ece94ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Schoolwork/Big Data Final/refactor/refactored_tfdif.csv')\n",
        "#('/content/drive/MyDrive/Schoolwork/Big Data Final/refactor/refactored_tfidf.csv')"
      ],
      "metadata": {
        "id": "NkZNwWafiM91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_df = df.drop('article_source', axis=1)\n",
        "word_df = word_df.drop('leftness', axis=1)\n",
        "word_df = word_df.drop('Unnamed: 0', axis=1)"
      ],
      "metadata": {
        "id": "RZB7UYanjntv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 10 most/least important words\n",
        "stupid_dict = {}\n",
        "for col in word_df.columns:\n",
        "    stupid_dict[col] = np.sum(word_df[col])\n",
        "stupid_list = [k for k, v in sorted(stupid_dict.items(), key=lambda item: item[1], reverse = True)]\n",
        "print(\"10 most important:\", stupid_list[0:10], \"\\n\\n\")\n",
        "print(\"10 least important:\", stupid_list[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6JcyWDlhbW9",
        "outputId": "37d15c75-d047-4879-dcb3-d787662f454c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 most important: ['trump', 'said', 'clinton', 'state', 'people', 'election', 'year', 'president', 'new', 'say'] \n",
            "\n",
            "\n",
            "10 least important: ['tolerable', 'compulsion', 'zeroed', 'herring', 'pettiness', 'vindictiveness', 'subsumed', 'unproductive', 'preface', 'perpetuates']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 10 most/least important words for left-leaning sources\n",
        "word_df_L = word_df[df['leftness'] == 1]\n",
        "stupid_dict = {}\n",
        "for col in word_df_L.columns:\n",
        "    stupid_dict[col] = np.sum(word_df_L[col])\n",
        "stupid_list = [k for k, v in sorted(stupid_dict.items(), key=lambda item: item[1], reverse = True)]\n",
        "print(\"10 most important:\", stupid_list[0:10], \"\\n\\n\")\n",
        "print(\"10 least important:\", stupid_list[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HMLXXPMj51q",
        "outputId": "24be76ff-6450-459b-8622-a3b15123714d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 most important: ['trump', 'said', 'people', 'clinton', 'state', 'mr', 'say', 'election', 'year', 'like'] \n",
            "\n",
            "\n",
            "10 least important: ['ul', 'vantiv', 'volz', 'walcott', 'warnerthuston', 'worldpay', 'xiaomi', 'yashaswini', 'yt', 'zieminski']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 10 most/least important words for right-leaning sources\n",
        "word_df_R = word_df[df['leftness'] == 0]\n",
        "stupid_dict = {}\n",
        "for col in word_df_R.columns:\n",
        "    stupid_dict[col] = np.sum(word_df_R[col])\n",
        "stupid_list = [k for k, v in sorted(stupid_dict.items(), key=lambda item: item[1], reverse = True)]\n",
        "print(\"10 most important:\", stupid_list[0:10], \"\\n\\n\")\n",
        "print(\"10 least important:\", stupid_list[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxeYqwD5k2X3",
        "outputId": "c5ef10bd-ca7d-45b1-87de-6356c1c0d422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 most important: ['trump', 'clinton', 'said', 'election', 'state', 'people', 'breitbart', 'news', 'president', 'obama'] \n",
            "\n",
            "\n",
            "10 least important: ['yearned', 'yeats', 'yonhap', 'yt', 'yuan', 'zadie', 'zengerle', 'zeroed', 'zieminski', 'zooming']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 10 most/least important words for center-leaning sources\n",
        "word_df_C = word_df[df['leftness'] == 1]\n",
        "stupid_dict = {}\n",
        "for col in word_df_C.columns:\n",
        "    stupid_dict[col] = np.sum(word_df_C[col])\n",
        "stupid_list = [k for k, v in sorted(stupid_dict.items(), key=lambda item: item[1], reverse = True)]\n",
        "print(\"10 most important:\", stupid_list[0:10], \"\\n\\n\")\n",
        "print(\"10 least important:\", stupid_list[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBuczGVBk3s2",
        "outputId": "d75d7edd-04fb-4454-f90c-df98dd01283e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 most important: ['trump', 'said', 'people', 'clinton', 'state', 'mr', 'say', 'election', 'year', 'like'] \n",
            "\n",
            "\n",
            "10 least important: ['ul', 'vantiv', 'volz', 'walcott', 'warnerthuston', 'worldpay', 'xiaomi', 'yashaswini', 'yt', 'zieminski']\n"
          ]
        }
      ]
    }
  ]
}